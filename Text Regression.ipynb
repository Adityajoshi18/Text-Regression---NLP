{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.models import Model, Sequential\n#from keras.layers import Dense, Embedding, LSTM, Input, ReLU\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras import optimizers\nfrom keras.optimizers import Adam,Adamax,Nadam\nfrom keras.layers import Dense, Embedding, LSTM, Input, ReLU, Conv1D, GlobalMaxPooling1D, Dropout, Activation\n \nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/nnfl-lab-3-nlp/nlp_train.csv')\npd.set_option('display.max_colwidth',-1)\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/nnfl-lab-3-nlp/_nlp_test.csv\",encoding=\"utf-8\",index_col=0)\ndf = df.reset_index()\ndf = df.drop(['offensive_language'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_words = 5000\ntokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                                   lower=True,split=' ')\nprint(data['tweet'][0])\ntokenizer.fit_on_texts(data['tweet'].values)\nX = tokenizer.texts_to_sequences(data['tweet'].values)\nprint(X[0])\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\nmaxlen = max([len(x) for x in X])\nX = pad_sequences(X, maxlen=maxlen)\n\nprint(word_index)\nprint(\"Padded Sequences: \")\nprint(X)\nprint(X[0])\n\n\ntest = df.iloc[:,0]\ntest = list(test)\nprint(test)\n\nX_t = tokenizer.texts_to_sequences(test)\n\nX_t = pad_sequences(X_t, maxlen=maxlen)\n\n\nprint(X_t)\nprint(X_t[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = max([len(x) for x in X])\nmaxlen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_dim = 100\nlstm_out = 128\nbatch_size = 64\nmodel = Sequential()\nmodel.add(Embedding(num_words,\n                    embed_dim,\n                    input_length = maxlen))\nmodel.add(Dropout(0.20))\nmodel.add(Conv1D(250,\n                 3,\n                 padding='valid',\n                 activation='relu',\n                 strides=1))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(256))\nmodel.add(Dropout(0.2))\nmodel.add(Activation('relu'))\nmodel.add(Dense(1))\nmodel.add(Activation('relu'))\nmodel.summary()\noptimizer = optimizers.SGD(lr=0.001 * 5, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['offensive_language']\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelcheckpoint=ModelCheckpoint(\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, validation_data=(X_test,y_test), batch_size = batch_size, epochs = 30, callbacks=[earlystop,modelcheckpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# load weights into new model\nmodel.load_weights(\"weights.13-0.33.hdf5\")\nprint(\"Loaded model from disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = model.evaluate(X_test, y_test, batch_size = batch_size, callbacks=[earlystop])\nprint(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/nnfl-lab-3-nlp/_nlp_test.csv\",encoding=\"utf-8\",index_col=0)\ndf = df.reset_index()\ndf = df.drop(['offensive_language'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\ntest = df.iloc[:,0]\ntest = list(test)\nprint(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#num_words = 5000\n#tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n                                   #lower=True,split=' ')\n#print(data['tweet'][0])\n#tokenizer.fit_on_texts(data['tweet'].values)\nX_t = tokenizer.texts_to_sequences(test)\n\n#word_index = tokenizer.word_index\n#print('Found %s unique tokens.' % len(word_index))\n\n\nX_t = pad_sequences(X_t, maxlen=maxlen)\n\n\nprint(X_t)\nprint(X_t[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_1 = 3.0\nfor i in range(len(y_pred)):\n    temp = y_pred[i]\n    if temp > temp_1:\n        temp = temp_1\n    y_pred[i] = temp\n\n\n        \n\n    \n        \n    \n        \n        \n    \n    \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndf[\"offensive_language\"] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):\n  csv = df.to_csv(index=False)\n  b64 = base64.b64encode(csv.encode())\n  payload = b64.decode()\n  html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\"target=\"_blank\">{title}</a>'\n  html = html.format(payload=payload,title=title,filename=filename)\n  return HTML(html)\ncreate_download_link(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
